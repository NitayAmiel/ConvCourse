{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install PyWavelets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-7Al41S684T",
        "outputId": "ac12f491-deba-4427-acca-d548106f9bd1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.10/dist-packages (1.7.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.10/dist-packages (from PyWavelets) (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "VLXrfPA9ztZr",
        "outputId": "a62cddeb-6bf2-4d5b-8ab3-24e60cdeb02f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-1ed20ca3e6b4>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mUSE_GLOBAL_DEPS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0m_load_global_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0;31m# Appease the type checker; ordinarily this binding is inserted by the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pywt\n",
        "import numpy as np\n",
        "\n",
        "def get_wavelet_kernels(wavelet_name='haar'):\n",
        "    wavelet = pywt.Wavelet(wavelet_name)\n",
        "\n",
        "    # Get low-pass and high-pass filters for decomposition\n",
        "    filter_bank = wavelet.filter_bank  # (dec_lo, dec_hi, rec_lo, rec_hi)\n",
        "    dec_lo = np.outer(filter_bank[0], filter_bank[0])  # Low-pass filter in 2D\n",
        "    dec_hi = np.outer(filter_bank[1], filter_bank[1])  # High-pass filter in 2D\n",
        "\n",
        "    # Create the wavelet filters for 2D convolution\n",
        "    filters = torch.tensor([dec_lo, dec_hi], dtype=torch.float32)\n",
        "\n",
        "    return filters\n",
        "\n",
        "# Example: Haar wavelet kernel\n",
        "wavelet_kernels = get_wavelet_kernels('haar')\n",
        "print(\"Wavelet kernels: \", wavelet_kernels.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class WaveletConv2d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, wavelet_name='haar', stride=1, padding=0):\n",
        "        super(WaveletConv2d, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "\n",
        "        # Create wavelet kernels\n",
        "        wavelet_kernels = get_wavelet_kernels(wavelet_name)\n",
        "        wavelet_kernels = wavelet_kernels.unsqueeze(1)  # Add input channel dimension\n",
        "\n",
        "        # Repeat wavelet kernels to match out_channels\n",
        "        # out_channels should be divisible by the number of wavelet kernels (here assumed as 1 for simplicity)\n",
        "        self.filters = nn.Parameter(wavelet_kernels.repeat(self.out_channels, 1, 1, 1), requires_grad=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Perform convolution using wavelet kernels\n",
        "        # Ensure `groups=1` if not performing grouped convolutions\n",
        "        x = nn.functional.conv2d(x, self.filters, stride=self.stride, padding=self.padding, groups=1)\n",
        "        return x\n",
        "\n",
        "\n",
        "class WaveletCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(WaveletCNN, self).__init__()\n",
        "        # Wavelet-based convolution layers\n",
        "        self.wavelet_conv1 = WaveletConv2d(in_channels=1, out_channels=16, wavelet_name='haar', stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.wavelet_conv2 = WaveletConv2d(in_channels=16, out_channels=32, wavelet_name='haar', stride=1, padding=1)\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(32 * 7 * 7, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Pass through wavelet-based convolutions\n",
        "        x = self.pool(torch.relu(self.wavelet_conv1(x)))\n",
        "        x = self.pool(torch.relu(self.wavelet_conv2(x)))\n",
        "\n",
        "        # Flatten for fully connected layers\n",
        "        x = x.view(-1, 32 * 7 * 7)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Example usage\n",
        "model = WaveletCNN()\n",
        "x = torch.randn(1, 1, 28, 28)  # Batch size 1, 1 channel, 28x28 image\n",
        "output = model(x)\n",
        "print(output)\n"
      ],
      "metadata": {
        "id": "1Zz7m1_J6uHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pywt\n",
        "import numpy as np\n",
        "\n",
        "def get_wavelet_kernels(wavelet_name='haar'):\n",
        "    wavelet = pywt.Wavelet(wavelet_name)\n",
        "\n",
        "    # Get low-pass and high-pass filters for decomposition\n",
        "    filter_bank = wavelet.filter_bank  # (dec_lo, dec_hi, rec_lo, rec_hi)\n",
        "    dec_lo = np.outer(filter_bank[0], filter_bank[0])  # Low-pass filter in 2D\n",
        "    dec_hi = np.outer(filter_bank[1], filter_bank[1])  # High-pass filter in 2D\n",
        "\n",
        "    # Create the wavelet filters for 2D convolution\n",
        "    filters = torch.tensor([dec_lo, dec_hi], dtype=torch.float32)\n",
        "\n",
        "    return filters\n",
        "\n",
        "class WaveletConv2d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, wavelet_name='haar', stride=1, padding=0):\n",
        "        super(WaveletConv2d, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "\n",
        "        # Get wavelet kernels (2 filters: low-pass and high-pass)\n",
        "        wavelet_kernels = get_wavelet_kernels(wavelet_name)  # Shape: (2, filter_height, filter_width)\n",
        "\n",
        "        # Expand to match in_channels and out_channels\n",
        "        # Repeat the filters to match the required number of channels\n",
        "        filters = wavelet_kernels.unsqueeze(1)  # Shape: (2, 1, filter_height, filter_width)\n",
        "        filters = filters.repeat(out_channels // 2, in_channels, 1, 1)  # Adjust to match in_channels and out_channels\n",
        "\n",
        "        # Register the filters as a non-learnable parameter\n",
        "        self.filters = nn.Parameter(filters, requires_grad=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Perform convolution using wavelet kernels\n",
        "        x = nn.functional.conv2d(x, self.filters, stride=self.stride, padding=self.padding)\n",
        "        return x\n",
        "\n",
        "class WaveletCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(WaveletCNN, self).__init__()\n",
        "        # Wavelet-based convolution layers\n",
        "        self.wavelet_conv1 = WaveletConv2d(in_channels=1, out_channels=16, wavelet_name='haar', stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.wavelet_conv2 = WaveletConv2d(in_channels=16, out_channels=32, wavelet_name='haar', stride=1, padding=1)\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(32 * 7 * 7, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Pass through wavelet-based convolutions\n",
        "        x = self.pool(torch.relu(self.wavelet_conv1(x)))  # Output: [batch_size, 16, 14, 14]\n",
        "        x = self.pool(torch.relu(self.wavelet_conv2(x)))  # Output: [batch_size, 32, 7, 7]\n",
        "\n",
        "        # Flatten for fully connected layers\n",
        "        x = x.view(-1, 32 * 7 * 7)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Example usage\n",
        "model = WaveletCNN()\n",
        "x = torch.randn(1, 1, 28, 28)  # Batch size 1, 1 channel, 28x28 image\n",
        "output = model(x)\n",
        "print(output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cu3qleAJ-DOa",
        "outputId": "db86c647-2f44-4a81-bb68-899a3713cb19"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-a5ca9e1a70a1>:15: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  filters = torch.tensor([dec_lo, dec_hi], dtype=torch.float32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  6.8028,  -4.7056,   3.5435,   4.5865,   2.8061,  -3.7799,   4.0897,\n",
            "           6.8766,  -8.1368, -14.6483]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Correlation computation***"
      ],
      "metadata": {
        "id": "712PncCZan38"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.integrate import dblquad\n",
        "\n",
        "# Assume U_x is defined somewhere and returns a complex number\n",
        "def U_x(u, lambd, alpha):\n",
        "    # Example of how it could be structured\n",
        "    # return some complex function based on u, lambd, and alpha\n",
        "    pass\n",
        "\n",
        "def C_x(lambd, alpha, lambd_prime, alpha_prime, u_bounds):\n",
        "    \"\"\"\n",
        "    Calculate C_x(λ, α, λ', α') by integrating U_x(u, λ, α) * conj(U_x(u, λ', α')) over R^2.\n",
        "\n",
        "    Args:\n",
        "    - lambd: λ parameter.\n",
        "    - alpha: α parameter.\n",
        "    - lambd_prime: λ' parameter.\n",
        "    - alpha_prime: α' parameter.\n",
        "    - u_bounds: The bounds of integration for the u vector in R^2, given as ((u1_min, u1_max), (u2_min, u2_max)).\n",
        "\n",
        "    Returns:\n",
        "    - result: The value of the integral.\n",
        "    \"\"\"\n",
        "\n",
        "    # Define the real and imaginary parts of the function to integrate\n",
        "    def integrand(u1, u2, lambd, alpha, lambd_prime, alpha_prime):\n",
        "        u = np.array([u1, u2])\n",
        "        return U_x(u, lambd, alpha) * np.conj(U_x(u, lambd_prime, alpha_prime))\n",
        "\n",
        "    # Perform the integration over u1 and u2 (R^2 space)\n",
        "    u1_bounds, u2_bounds = u_bounds\n",
        "    result, error = dblquad(\n",
        "        lambda u1, u2: np.real(integrand(u1, u2, lambd, alpha, lambd_prime, alpha_prime)),  # Real part\n",
        "        u1_bounds[0], u1_bounds[1],\n",
        "        lambda u1: u2_bounds[0], lambda u1: u2_bounds[1]\n",
        "    )\n",
        "\n",
        "    result_imag, error_imag = dblquad(\n",
        "        lambda u1, u2: np.imag(integrand(u1, u2, lambd, alpha, lambd_prime, alpha_prime)),  # Imaginary part\n",
        "        u1_bounds[0], u1_bounds[1],\n",
        "        lambda u1: u2_bounds[0], lambda u1: u2_bounds[1]\n",
        "    )\n",
        "\n",
        "    # Combine the real and imaginary parts to form the complex result\n",
        "    return result + 1j * result_imag\n",
        "\n",
        "# Example usage (assuming bounds of integration are known)\n",
        "# u_bounds = ((u1_min, u1_max), (u2_min, u2_max))\n",
        "# result = C_x(lambd, alpha, lambd_prime, alpha_prime, u_bounds)\n"
      ],
      "metadata": {
        "id": "i0EDJVgIalPi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}